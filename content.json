{"meta":{"title":"牟宗琳的博客","subtitle":null,"description":null,"author":"John Doe","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"","slug":"InnoDB MVCC","date":"2020-01-17T02:59:26.126Z","updated":"2020-01-17T03:01:54.691Z","comments":true,"path":"2020/01/17/InnoDB MVCC/","link":"","permalink":"http://yoursite.com/2020/01/17/InnoDB MVCC/","excerpt":"","text":"InnoDB MVCC1.什么是MVCCMVCC（Multiversion Concurrency Control），中文全称叫中文全称叫多版本并发控制，是现代数据库（包括 MySQL、Oracle、PostgreSQL 等）引擎实现中常用的处理读写冲突的手段，目的在于提高数据库高并发场景下的吞吐性能。 如此一来不同的事务在并发过程中，SELECT 操作可以不加锁而是通过 MVCC 机制读取指定的版本历史记录，并通过一些手段保证保证读取的记录值符合事务所处的隔离级别，从而解决并发场景下的读写冲突。 下面举一个多版本读的例子，例如两个事务 A 和 B 按照如下顺序进行更新和读取操作 在事务 A 提交前后，事务 B 读取到的 x 的值是什么呢？答案是：事务 B 在不同的隔离级别下，读取到的值不一样。 如果事务 B 的隔离级别是读未提交（RU），那么两次读取均读取到 x 的最新值，即 20。 如果事务 B 的隔离级别是读已提交（RC），那么第一次读取到旧值 10，第二次因为事务 A 已经提交，则读取到新值 20。 如果事务 B 的隔离级别是可重复读或者串行（RR，S），则两次均读到旧值 10，不论事务 A 是否已经提交。 可见在不同的隔离级别下，数据库通过 MVCC 和隔离级别，让事务之间并行操作遵循了某种规则，来保证单个事务内前后数据的一致性。 2.为什么需要MVCCInnoDB 相比 MyISAM 有两大特点，一是支持事务而是支持行级锁，事务的引入带来了一些新的挑战。相对于串行处理来说，并发事务处理能大大增加数据库资源的利用率，提高数据库系统的事务吞吐量，从而可以支持可以支持更多的用户。但并发事务处理也会带来一些问题，主要包括以下几种情况： 实现隔离机制的方法主要有两种： 加读写锁 一致性快照读，即 MVCC 3.InnoDB MVCC实现原理InnoDB中MVCC的实现方式为：每一行记录都有两个隐藏列：DATA_TRX_ID,DATA_ROLL_PTR(如果没有主键，则还会多一个隐藏的主键列)。 DATA_TRX_ID 记录最近更新这条行记录的事务ID，大小为6个字节 DATA_ROLL_PTR 表示指向该回滚段(rollback segment)的 指针，大小为7个字节，InnoDB便是通过这个指针找到之前版本的数据，改行记录上所有旧版本，在undo中投通过链表形式组织。 DB_ROW_ID 行标识（隐藏单调自增id）,大小为6字节，如果没有主键,InnoDB会自动生成一个隐藏主键，因此会出现这个列 。另外，每条记录的头信息(record header)里都有一个专门的bit（deleted_flag）来表示当前记录是否已经删除。 3.1 如何组织版本链1关于Redo log 和 Undo log的相关概念自行查找资料 上文提到，在多个事务并行操作某行数据的情况下，不同事务对该行数据的 UPDATE 会产生多个版本，然后通过回滚指针组织成一条 Undo Log 链，这节我们通过一个简单的例子来看一下 Undo Log 链是如何组织的，DATA_TRX_ID 和 DATA_ROLL_PTR 两个参数在其中又起到什么样的作用。 还是以上文 MVCC 的例子，事务 A 对值 x 进行更新之后，该行即产生一个新版本和旧版本。假设之前插入该行的事务 ID 为 100，事务 A 的 ID 为 200，该行的隐藏主键为 1。 事务A 的操作过程为: 对 DB_ROW_ID = 1 的这行记录加排他锁。 把该行原本的值拷贝到 undo log 中，DB_TRX_ID 和 DB_ROLL_PTR 都不动。 修改该行的值这时产生一个新版本，更新 DATA_TRX_ID 为修改记录的事务 ID，将 DATA_ROLL_PTR 指向刚刚拷贝到 undo log 链中的旧版本记录，这样就能通过 DB_ROLL_PTR 找到这条记录的历史版本。如果对同一行记录执行连续的 UPDATE，Undo Log 会组成一个链表，遍历这个链表可以看到这条记录的变迁。 记录redo log,包括undo log中的修改。 那么 INSERT 和 DELETE 会怎么做呢？其实相比 UPDATE 这二者很简单，INSERT 会产生一条新纪录，它的 DATA_TRX_ID 为当前插入记录的事务 ID；DELETE 某条记录时可看成是一种特殊的 UPDATE，其实是软删，真正执行删除操作会在 commit 时，DATA_TRX_ID 则记录下删除该记录的事务 ID。 3.2 如何实现一致性读 ReadView在 RU 隔离级别下，直接读取版本的最新记录就 OK，对于 SERIALIZABLE 隔离级别，则是通过加锁互斥来访问数据，因此不需要 MVCC 的帮助。因此 MVCC 运行在 RC 和 RR这两个隔离级别下，当 InnoDB 隔离级别设置为二者其一时，在 SELECT 数据时就会用到版本链 核心问题是版本链中哪些版本对当前事务可见？ InnoDB 为了解决这个问题，设计了 ReadView（可读视图）的概念。 3.3 RR下ReadView的生成在RR隔离级别下，每个事务touch first read时（本质上就是执行第一个 SELECT语句时，后续所有的 SELECT 都是复用这个 ReadView，其它 update, delete, insert 语句和一致性读 snapshot 的建立没有关系），会将当前系统中的所有的活跃事务拷贝到一个列表生成ReadView。 4.举个例子数据表user 加入隐藏列 假如有两个事务开启 在1处时，数据是这样的： 于此同时，需要建立一个Read View的数据结构，它有三个部分： 当前活跃的事务列表[101,102] Tmin,就是活跃事务的最小值， 在这里 Tmin = 101 Tmax, 是系统中最大事务ID（不管事务是否提交）加上1。 在这里例子中，Tmax = 103 在2的部分事务102做了修改，此时数据是这样的： 关键部分，下面的算法用来判断这些数据版本哪些是是对当前事务可见的 Read View结构 当前活跃的事务列表[101,102] Tmin,就是活跃事务的最小值， 在这里 Tmin = 101 Tmax, 是系统中最大事务ID（不管事务是否提交）加上1。 在这里例子中，Tmax = 103 对于上述例子，第一次读取时： 取出要读取的数据，取出事务ID赋值给变量tid,tid=100。 Tmin=101,tid&lt;Tmin 可见 第二次读取时： tid=102 Tmin=101,当前事务事务id=101,进入下个判断流程 tid=102,Tmax=103,走入tid在ReadView中？ tid=102在ReadView中，沿着回滚指针找到上一行，将事务id赋值给tid,tid=100 读取的数据和第一次相同 保证了可重复读 5.一个争议点并非所有的情况都能套用MVCC读的判断流程，例如RR级别下 1.假设transaction A trx_id =200 ，transaction B trx_id =300,且事务B先于事务A提交，按照MVCC的判断流程，事务A生成的ReadView为[200],最新版本行记录DATA_TRX_ID=300,300比200大，照理不能访问，但是事务A实际上读到了事务B已经提交的修改。 6写在最后RC、RR 两种隔离级别的事务在执行普通的读操作时，通过访问版本链的方法，使得事务间的读写操作得以并发执行，从而提升系统性能。RC、RR 这两个隔离级别的一个很大不同就是生成 ReadView 的时间点不同，RC 在每一次 SELECT 语句前都会生成一个 ReadView，事务期间会更新，因此在其他事务提交前后所得到的 m_ids 列表可能发生变化，使得先前不可见的版本后续又突然可见了。而 RR 只在事务的第一个 SELECT 语句时生成一个 ReadView，事务操作期间不更新。","categories":[],"tags":[]},{"title":"如何备份博客","slug":"如何备份博客","date":"2020-01-17T02:58:44.018Z","updated":"2020-01-17T02:58:44.019Z","comments":true,"path":"2020/01/17/如何备份博客/","link":"","permalink":"http://yoursite.com/2020/01/17/如何备份博客/","excerpt":"","text":"本文转载自怎么去备份你的Hexo博客 前言作为一个写代码的人来说，保存和备份是非常重要的，所以随手保存和存有备份已经成为我的习惯了。使用Hexo在github搭建的博客，仓库里只有生成的静态网页文件，是没有Hexo的源文件的，如果现在这个电脑出现了什么问题，那就麻烦了，所以我就研究了一下怎么备份。备份的教程和搭建的教程比起来简直是少的可怜，好不容易找到一份教程，却是写的非常高深，个人觉得不应该是那么复杂的，所以果断放弃，就在我准备自己瞎搞得时候，终于让我看到了一份简单明了的教程，因为测试成功了，所以我需要把过程记录下来，以后忘了还可以有个参考 华丽的分隔线，前面的碎碎念可以略过，下面才是正文。 正文针对博客已经搭建并发布过文章的。 1、在你的博客仓库创建一个分支Hexo（这个命名随意）； 2、设置Hexo为默认分支（不知道怎么设的可以百度）； 3、将博客仓库clone至本地，将之前的Hexo文件夹中的 _config.yml，themes/，source，scffolds/，package.json，.gitignore复制到你克隆下来的仓库文件夹，即Username.github.io；（Username是你自己的用户名） 4、将themes/next/(我用的是NexT主题)中的.git/删除，否则无法将主题文件夹push； 5、在Username.github.io；文件夹执行npm install，npm install hexo-deployer-git(这里可以看看分支是不是显示为Hexo) 示例01.png 6、执行git add，git commit -m &quot;提交文件&quot;，git push origin Hexo来提交Hexo网站源文件； 注意： 示例02.png 7、执行hexo g -d 生成静态网页部署到github上。 这样，Username.github.io仓库就有master分支保存静态网页，hexo分支保存源文件。 修改在本地对博客修改（包括修改主题样式、发布新文章等）后 1、执行git add，git commit -m &quot;提交文件&quot;，git push origin Hexo来提交Hexo网站源文件； 2、执行hexo g -d 生成静态网页部署到github上； （每次发布重复这两步，它们之间没有严格的顺序） 恢复换电脑想改博客： 1、安装git； 2、安装Nodejs和npm； 3、使用克隆命令将仓库拷贝至本地； 4、在文件夹内执行命令npm install hexo-cli -g、npm install、npm install hexo-deployer-git； 附录Hexo的源文件说明： 1、_config.yml站点的配置文件，需要拷贝； 2、themes/主题文件夹，需要拷贝； 3、source博客文章的.md文件，需要拷贝； 4、scaffolds/文章的模板，需要拷贝； 5、package.json安装包的名称，需要拷贝； 6、.gitignore限定在push时哪些文件可以忽略，需要拷贝； 7、.git/主题和站点都有，标志这是一个git项目，不需要拷贝； 8、node_modules/是安装包的目录，在执行npm install的时候会重新生成，不需要拷贝； 9、public是hexo g生成的静态网页，不需要拷贝； 10、.deploy_git同上，hexo g也会生成，不需要拷贝； 11、db.json文件，不需要拷贝。 不需要拷贝的文件正是.gitignore中所忽略的。 其他在github上直接创建分支的方法，直接输入新的分支名，回车即可。","categories":[{"name":"博客","slug":"博客","permalink":"http://yoursite.com/categories/博客/"}],"tags":[{"name":"备忘","slug":"备忘","permalink":"http://yoursite.com/tags/备忘/"}]},{"title":"深入理解kafka读书笔记","slug":"kafka-1-基本概念","date":"2019-11-02T11:43:08.668Z","updated":"2019-07-06T09:47:37.622Z","comments":true,"path":"2019/11/02/kafka-1-基本概念/","link":"","permalink":"http://yoursite.com/2019/11/02/kafka-1-基本概念/","excerpt":"","text":"kafka 读书笔记一.术语​ Producer:生产者，也就是发送消息的一方。生产者负责创建消息，然后将其投递到Kafka中 Consumer:消费者,也就是接收消息的一方。消费者连接到Kafka上并接收消息，进而进行相应的业务处理。 Broker:服务代理节点。对于kafka而言，Broker可以简单的看做一个独立的kafka服务节点或Kafka服务实例。大多数情况下可以将Broker看作一台Kafka服务器，前提是这台服务器上只部署了一个Kafka实例。一个或多个Broker组成了一个Kafka集群。 在Kafka中还有两个重要的概念——主题（Topic）与分区(Partition)。Kafka中的消息以主题为单位进行归类，生产者负责将消息发送到特定的主题，而消费者负责订阅主题进行消费。 主题是一个逻辑上的概念，他可以细分多个分区，一个分区只属于单个主题。 同一主题下的不同分区包含的消息是不同的.分区在存储层面可以看做一个可追加的日志文件，消息被分区追加到分区日志文件的时候会分配一个特定的偏移量（offset）。offset是消息在分区中的唯一标识，Kafka通过它来保证消息在分区内的顺序性，不过offset不跨越分区，也就是说Kafka保证分区有序而不是主题有序。 如图所示，主题中有4个分区，消息被顺序追加到每个日志尾部。Kafka中的分区可以分布在不同的服务器上(broker),也就是说一个主题可以横跨多个broker.以此来提供比单个broker更强大的性能。 每一条消息被发送到 broker 之前，会根据分区规则选择存储到哪个具体的分区 。 如果分区规则设定得合理，所有的消息都可以均匀地分配到不同的分区中 。 如果一个主题只对应一个文件，那么这个文件所在的机器 I/O 将会成为这个主题的性能瓶颈，而分区解决了这个问题 。 在创建主题的时候可以通过指定的参数来设置分区的个数，当然也可以在主题创建完成之后去修改分区的数量，通过增加分区的数量可以实现水平扩展。 Kafka 为分区引入了多副本 （ Replica ） 机制， 通过增加副本数量可以提升容灾能力。同一分区的不同副本中保存的是相同的消息（在同一时刻，副本之间并非完全一样），副本之间是“ 一主多 从”的关系，其中 leader 副本负 责处理读写请求 ， follower 副本只负 责与 lead er 副本的消息同步。副本处于不同的 broker 中 ，当 leader 副本出现故障时，从 follower 副本中重新选举新的 leader 副本对外提供服务。 Kafka 通过多副本机制实现了故障的自动转移，当 Kafka 集群中某个 broker 失效时仍然能保证服务可用 。 如图 3 所示， Kafka 集群中有 4 个 broker，某个主题中有 3 个分区，且副本因子（即副本个数〉也为 3 ，如此每个分区便有 l 个 leader 副本和 2 个 follower 副本。生产者和消费者只与 leader副本进行交互，而 follower 副本只负责消息的同步，很多时候 follower 副本中的消息相对 leader副本而言会有一定的滞后。 Kafka 消费端也具备一 定 的 容灾能力。 Consumer 使用拉 （ Pull ）模式从服务端拉取消息，并且保存消费 的具体位置 ， 当消费者看机后恢复上线时可以根据之前保存的消费位置重新拉取需要的消息进行消 费 ，这样就不会造成消息丢失 。 分区中 的所有副本统称为 AR ( Assigned Replicas ） 。 所有与 leader 副本保持一定程度同步的副本（包括 leader 副本在内〕组成 ISR （In-Sync Replicas ) , ISR 集合是 AR 集合中 的一个子集 。 消息会先发送到leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步，同步期间内 follower 副本相对于leader 副本而言会有一定程度的滞后 。 前面所说的“一定程度的同步”是指可忍受的滞后范围，这个范围可以通过参数进行配置 。 与 leader 副本同步滞后过多的副本（不包括 leader 副本）组成 OSR ( Out-of-Sync Replicas ），由此可见， AR=ISR+OSR 。在正常情况下， 所有的 follower 副本都应该与 leader 副本保持一定程度 的同步，即 AR=ISR,OSR 集合为空。 leader 副本负 责维护和跟踪 ISR 集合中所有 follower 副 本 的滞后状态， 当 follower 副本落后太多或失效时， leader 副本会把它从 ISR 集合中剔除 。 如果 OSR 集合中有 follower 副本 “追上’了 leader 副本，那么 leader 副本会把它从 OSR 集合转移至 ISR 集合 。 默认情况下， 当 leader 副本发生故障时，只 有在 ISR 集合中的副本才有资格被选举为新的 leader， 而在 OSR 集合中的副本则没有任何机会（不过这个原则也可以通过修改相应的参数配置来改变）。 ISR 与 HW 和 LEO 也有紧密的关系 。 HW 是 High Watermark 的缩写，俗称高水位，它标识了 一个特定 的消息偏移量（ offset ），消费者只能拉取到这个 offset 之前的消息 。 如图 4 所示，它代表一个日志文件，这个日志文件中有 9 条消息，第一条消息的 offset (LogStartOffset)为0，最后一条的offset为8，offset为9的消息用虚线框标识，代表下一条待写入的消息。日志文件的HW为6，标识消费者只能拉取到offset在0到5之间的消息，而offset为6的消息对消费者而言是不可见的。 ![123](&lt;https://raw.githubusercontent.com/mzl1989325/ImageBed/master/mq/kafka/offset.jpg&gt;) ​ 图4 分区中各种偏移量说明 ​ LEO是LogEndOffset的缩写，它标识当前日志文件中下一条待写入消息的offset,图4中offset为9的位置即为当前日志文件的LEO，LEO的大小相当于当前日志分区中最后一条消息的offset值加1.分区ISR集合中的每个副本都会委会自身的LEO，而ISR集合中最小的LEO即为分区的HW,对于消费者而言只能消费HW之前的消息。 ​ 如下图所示，加入某个分区的ISR集合找那个有3个副本，即一个leader副本和2个follower副本，此时分区的LEO和HW都为3。消息3和消息4从生产者发出之后会被先存入leader副本，如图6所示。 ​ 在消息写入leader副本之后，follower副本会发送拉去请求来拉去消息3和消息4以进行消息同 步。 ​ 在同步过程中，不同的 follower 副本的同步效率也不尽相同。如图 7 所示， 在某一时刻follower1 完全跟上了 leader 副本而 follower2 只同步了消息 3 ，如此 leader 副本的 LEO 为 5,follower1 的 LEO 为 5 , follower2 的 LEO 为 4 ， 那么当前分区的 HW 取最小值 4 ，此时消费者可以消 费到 offset 为 0 至 3 之间的消息。 ​ 如图8所示，所有的副本都成功写入了消息3和消息4，整个分区的HW和LEO都变为5，因此消费者可以消费到offset为4的消息了。 由此可见， Kafka 的复制机制既不是完全的同步复制，也不是单纯的异步复制。事实上，同步复制要求所有能工作的 follower 副本都复制完，这条消息才会被确认为已成功提交，这种复制方式极大地影响了性能。而在异步复制方式下， follower 副本异步地从 leader 副本中 复制数据，数据只要被 leader 副本写入就被认为已经成功提交。在这种情况下，如果 follower 副本都还没有复制完而落后于 leader 副本，突然 leader 副本着机，则会造成数据丢失。 Kafka 使用的这种 ISR 的方式则有效地权衡了数据可靠性和性能之间的关系。","categories":[{"name":"中间件","slug":"中间件","permalink":"http://yoursite.com/categories/中间件/"}],"tags":[{"name":"mq","slug":"mq","permalink":"http://yoursite.com/tags/mq/"},{"name":"kafka","slug":"kafka","permalink":"http://yoursite.com/tags/kafka/"}]},{"title":"java并发编程的艺术读书笔记（volatile）","slug":"java并发编程的艺术读书笔记-volatile","date":"2019-11-02T11:43:08.646Z","updated":"2019-08-31T09:43:49.906Z","comments":true,"path":"2019/11/02/java并发编程的艺术读书笔记-volatile/","link":"","permalink":"http://yoursite.com/2019/11/02/java并发编程的艺术读书笔记-volatile/","excerpt":"","text":"java 并发编程的艺术读书笔记（volatile）volatile的内存语义一.volatile的特性 可见性：对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。 原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。 二.volatile写-读建立的happens-before关系12345678910111213class VolatileExample &#123; int a = 0; volatile boolean flag = false; public void writer() &#123; a = 1; // 1 flag = true; // 2 &#125; public void reader() &#123; if (flag) &#123; // 3 int i = a; // 4 &#125; &#125;&#125; 假设线程A执行writer()方法之后，线程B执行reader()方法。根据happens-before规则，这个过程建立的happens-before关系可以分为3类： 根据程序次序规则，1 happens-before 2;3 happens-before 4 根据程序次序规则，1 happens-before 2;3 happens-before 4 根据happens-before的传递性规则，1 happens-before 4 三.volatile写-读的内存语义当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存 四.volatile读的内存语义如下：当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量 五.volatile内存语义的实现为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能。为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略 。 在每个volatile写操作的前面插入一个StoreStore屏障 。 在每个volatile写操作的后面插入一个StoreLoad屏障 。 在每个volatile读操作的后面插入一个LoadLoad屏障 。 在每个volatile读操作的后面插入一个LoadStore屏障 。 volatile写插入内存屏障后生成的指令序列示意图 volatile读插入内存屏障后生成的指令序列示意图 图中的StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。 这里比较有意思的是，volatile写后面的StoreLoad屏障。此屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序。因为编译器常常无法准确判断在一个volatile写的后面是否需要插入一个StoreLoad屏障（比如，一个volatile写之后方法立即return）。为了保证能正确实现volatile的内存语义，JMM在采取了保守策略：在每个volatile写的后面，或者在每个volatile读的前面插入一个StoreLoad屏障。从整体执行效率的角度考虑，JMM最终选择了在每个volatile写的后面插入一个StoreLoad屏障。因为volatile写-读内存语义的常见使用模式是：一个写线程写volatile变量，多个读线程读同一个volatile变量。当读线程的数量大大超过写线程时，选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升。从这里可以看到JMM在实现上的一个特点：首先确保正确性，然后再去追求执行效率。 图中的LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。 上述volatile写和volatile读的内存屏障插入策略非常保守。在实际执行时，只要不改变volatile写-读的内存语义，编译器可以根据具体情况省略不必要的屏障。下面通过具体的示例代码进行说明 12345678910111213class VolatileBarrierExample &#123; int a; volatile int v1 = 1; volatile int v2 = 2; void readAndWrite() &#123; int i = v1; // 第一个volatile读 int j = v2; // 第二个volatile读 a = i + j; // 普通写 v1 = i + 1; // 第一个volatile写 v2 = j * 2; // 第二个 volatile写 &#125; … // 其他方法&#125; 注意，最后的StoreLoad屏障不能省略。因为第二个volatile写之后，方法立即return。此时编译器可能无法准确断定后面是否会有volatile读或写，为了安全起见，编译器通常会在这里插入一个StoreLoad屏障。 上面的优化针对任意处理器平台，由于不同的处理器有不同“松紧度”的处理器内存模型，内存屏障的插入还可以根据具体的处理器内存模型继续优化。以X86处理器为例，上图中除最后的StoreLoad屏障外，其他的屏障都会被省略 。 前面保守策略下的volatile读和写，在X86处理器平台可以优化成如下图所示。 X86处理器仅会对写-读操作做重排序。X86不会对读-读、读-写和写-写操作做重排序，因此在X86处理器中会省略掉这3种操作类型对应的内存屏障。在X86中，JMM仅需在volatile写后面插入一个StoreLoad屏障即可正确实现volatile写-读的内存语义。这意味着在X86处理器中，volatile写的开销比volatile读的开销会大很多（因为执行StoreLoad屏障开销会比较大）","categories":[{"name":"多线程","slug":"多线程","permalink":"http://yoursite.com/categories/多线程/"}],"tags":[{"name":"JMM","slug":"JMM","permalink":"http://yoursite.com/tags/JMM/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://yoursite.com/tags/读书笔记/"},{"name":"volatile","slug":"volatile","permalink":"http://yoursite.com/tags/volatile/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-11-02T11:43:08.621Z","updated":"2019-07-06T09:06:48.540Z","comments":true,"path":"2019/11/02/hello-world/","link":"","permalink":"http://yoursite.com/2019/11/02/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}